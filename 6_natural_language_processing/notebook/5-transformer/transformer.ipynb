{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f5fba18-c720-4c86-89a2-1dc6cf4c6b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd33a0c0-6f6d-4d31-92c8-839668521d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset # load dataset from huggingface\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55013f5e-de60-4a53-9ae1-ada930718bb9",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04aee51b-ab39-46bc-9828-1013dbcf691f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"ted_talks_iwslt\", language_pair=(\"de\", \"en\"), year=\"2016\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29241ab8-8eb7-492d-85a6-da434d66c3e3",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d45fd204-06c5-4fcd-9fd8-fe594fcd39fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer(\"basic_english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e119548a-92c0-4f08-88ab-3bf7dc8d7330",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yield_tokens_from_hf(split):\n",
    "    for item in split:\n",
    "        de_text = item[\"translation\"][\"de\"]\n",
    "        en_text = item[\"translation\"][\"en\"]\n",
    "        yield tokenizer(de_text) + tokenizer(en_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2539b20f-5eda-4d0d-a34a-51be2d593a0d",
   "metadata": {},
   "source": [
    "## Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c553b1f-22cd-4195-af27-8004b7375ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split = dataset[\"train\"]\n",
    "vocab = build_vocab_from_iterator(yield_tokens_from_hf(train_split), specials=[\"<unk>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "643a6aba-2158-4c4e-8f7c-89e4e8294265",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_batch(batch):\n",
    "    for item in batch:\n",
    "        en_vector = vocab(tokenizer(item[\"translation\"][\"en\"]))\n",
    "        de_vector = vocab(tokenizer(item[\"translation\"][\"de\"]))\n",
    "    en_vector = torch.tensor(en_vector, dtype=torch.int64)\n",
    "    de_vector = torch.tensor(de_vector, dtype=torch.int64)\n",
    "    return en_vector, de_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22db633d-cee9-4661-83f8-e12db5179118",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset[\"train\"], batch_size=4, shuffle=False, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07478183-ab2d-4771-b24a-c37d55fe788e",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e44b6e3b-8e9c-4bb1-87ad-07988ac98567",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, src_vocab_size, trg_vocab_size, d_model=512, nhead=8, num_encoder_layers=6, num_decoder_layers=6):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.embedding_src = nn.Embedding(src_vocab_size, d_model)\n",
    "        self.embedding_trg = nn.Embedding(trg_vocab_size, d_model)\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            num_encoder_layers=num_encoder_layers,\n",
    "            num_decoder_layers=num_decoder_layers\n",
    "        )\n",
    "        self.fc = nn.Linear(d_model, trg_vocab_size)\n",
    "\n",
    "    def forward(self, src, trg):\n",
    "        src = self.embedding_src(src)\n",
    "        trg = self.embedding_trg(trg)\n",
    "        output = self.transformer(src, trg)\n",
    "        output = self.fc(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a842449-7a7a-4dc2-96f3-93be18d18f61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerModel(\n",
       "  (embedding_src): Embedding(28984, 64)\n",
       "  (embedding_trg): Embedding(28984, 64)\n",
       "  (transformer): Transformer(\n",
       "    (encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
       "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
       "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=64, out_features=28984, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TransformerModel(\n",
    "    src_vocab_size=len(vocab),\n",
    "    trg_vocab_size=len(vocab),\n",
    "    d_model=64,\n",
    "    nhead=1,\n",
    "    num_encoder_layers=1,\n",
    "    num_decoder_layers=1\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71cbb422-6704-4771-9557-0aa2009af319",
   "metadata": {},
   "source": [
    "## Loss and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ffea9e03-0133-4445-9b70-005f66e43a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3543cca9-5f19-4876-acc1-deeb467e08c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5dcef4-1e7e-4bd8-bb84-373cebbc683e",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8cdd4a09-f324-44a7-b66c-fe4827ede9b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    print(\"Epoch\", epoch)\n",
    "    for en_vector, de_vector in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(en_vector, de_vector)\n",
    "        output = output[1:].view(-1, len(vocab))\n",
    "        loss = criterion(output, de_vector[1:].view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f72f43-221b-42f3-ada6-53bdb93d4926",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
