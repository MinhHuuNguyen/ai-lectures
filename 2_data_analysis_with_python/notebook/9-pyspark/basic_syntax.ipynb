{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be68d779",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DoubleType\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24fa8f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a session\n",
    "spark = SparkSession.builder.appName(\"PySpark Introduction\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76774128",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_PATH = './data/datacamp_ecommerce.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a51a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(CSV_PATH)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df314a52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075266d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = spark.read.csv(CSV_PATH, header=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0caa19a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba69f88-e3ca-4db2-a78a-bb2c7c99676f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"InvoiceNo\", StringType(), True),\n",
    "    StructField(\"StockCode\", StringType(), True),\n",
    "    StructField(\"Description\", StringType(), True),\n",
    "    StructField(\"Quantity\", IntegerType(), True),\n",
    "    StructField(\"InvoiceDate\", StringType(), True),\n",
    "    StructField(\"UnitPrice\", DoubleType(), True),\n",
    "    StructField(\"CustomerID\", StringType(), True),\n",
    "    StructField(\"Country\", StringType(), True)\n",
    "])\n",
    "\n",
    "df = spark.read.csv(CSV_PATH, header=True, schema=schema)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73941d3f-ccb7-4f2f-a7a9-24a07d5882d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e695c4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.count()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6827556e",
   "metadata": {},
   "source": [
    "## 1. How many unique customers are present in the dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc519205",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.select('CustomerID').distinct().count()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "60f89b65",
   "metadata": {},
   "source": [
    "## 2. What country do most purchases come from?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4e7e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import countDistinct\n",
    "\n",
    "df.groupBy('Country').agg(countDistinct('InvoiceNo').alias('country_count')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f535b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import desc\n",
    "\n",
    "# with sort\n",
    "df.groupBy('Country').agg(countDistinct('InvoiceNo').alias('country_count')).orderBy(desc('country_count')).show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5c1ed007",
   "metadata": {},
   "source": [
    "## 3. When was the most recent/most early purchase made by a customer on the platform?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b4e889",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f54991",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import to_timestamp\n",
    "\n",
    "spark.sql('set spark.sql.legacy.timeParserPolicy=LEGACY')\n",
    "df = df.withColumn('InvoiceDate', to_timestamp('InvoiceDate', 'MM/dd/yyyy HH:mm'))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf3910d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1203b859",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import min as sql_func_min, max as sql_func_max\n",
    "\n",
    "df.select(sql_func_min(\"InvoiceDate\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6a9d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(sql_func_max(\"InvoiceDate\")).show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2be92f36",
   "metadata": {},
   "source": [
    "## 4. What was the highest/lowest purchase made by a customer on the platform?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ba2657",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ea7810",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('TotalPrice', df.Quantity * df.UnitPrice)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc01f1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aeebfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import sum as sql_func_sum, asc\n",
    "\n",
    "df.groupby('InvoiceNo') \\\n",
    "    .agg(sql_func_sum(df.Quantity * df.UnitPrice).alias('InvoiceTotalPrice')) \\\n",
    "    .orderBy(asc('InvoiceTotalPrice')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f995b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('InvoiceNo') \\\n",
    "    .agg(sql_func_sum('TotalPrice').alias('InvoiceTotalPrice')) \\\n",
    "    .orderBy(desc('InvoiceTotalPrice')).show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e958d3da",
   "metadata": {},
   "source": [
    "## 5. Other syntax"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bd6c0dd6",
   "metadata": {},
   "source": [
    "### 5.1. SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8078e5a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"CUSTOMER_DATA\")\n",
    "sql_df = spark.sql(\"SELECT * from CUSTOMER_DATA\")\n",
    "sql_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b68ac1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sql_df = spark.sql(\n",
    "    '''\n",
    "    SELECT InvoiceDate, CustomerID, TotalPrice\n",
    "    FROM CUSTOMER_DATA\n",
    "    WHERE CustomerID == 13047\n",
    "    '''\n",
    ")\n",
    "sql_df.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e63388de",
   "metadata": {},
   "source": [
    "### 5.2. Parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f7b961",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ./data/dummy_parquet_dataset/part-00000.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3607be-8986-45c7-8dff-6c444dc71fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "PARQUET_PATHS = glob('./data/dummy_parquet_dataset/*.parquet')\n",
    "PARQUET_PATHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf26692f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "par_df = spark.read.parquet(PARQUET_PATHS[0])\n",
    "par_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd85deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "par_df.count()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a0b09ef4",
   "metadata": {},
   "source": [
    "#### PySpark vs Pandas\n",
    "\n",
    "1. Read and concat 2 parquet files\n",
    "2. Drop `URL` column\n",
    "3. Filter `similarity` value higher than 0.4\n",
    "4. Create new `image_size` column by `HEIGHT * WIDTH`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c238d40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df_list = [spark.read.parquet(p) for p in PARQUET_PATHS]\n",
    "spark_df_list[0].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42a1215-e524-446c-acb1-1db207c58624",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import DataFrame\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d688d070-59c7-4a73-8898-b47c111b7e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df = reduce(DataFrame.unionAll, spark_df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71a1fda",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spark_df = spark_df.drop('URL')\n",
    "spark_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88ddc04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spark_df = spark_df.filter(spark_df.similarity > 0.4)\n",
    "spark_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9671fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dec8ef5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spark_df = spark_df.withColumn('image_size', spark_df.HEIGHT * spark_df.WIDTH)\n",
    "spark_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97102330",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b6e5f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "spark_df = reduce(DataFrame.unionAll, [spark.read.parquet(p) for p in PARQUET_PATHS]) \\\n",
    "    .drop('URL') \\\n",
    "    .filter(col('similarity') > 0.4) \\\n",
    "    .withColumn('image_size', col('HEIGHT') * col('WIDTH'))\n",
    "spark_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4176189c-33f2-4299-976e-246e0326bbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df.count()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1d7cc558",
   "metadata": {},
   "source": [
    "``` bash\n",
    "pip install pyarrow\n",
    "```\n",
    "to handle parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40285f0-486c-4ecc-9fd6-334ab23df564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f008463",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e06413",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "df = pd.concat([\n",
    "    pd.read_parquet(path) for path in PARQUET_PATHS\n",
    "])\n",
    "df = df.drop(columns=['URL'])\n",
    "df = df.loc[df.similarity > 0.4]\n",
    "df['image_size'] = df.HEIGHT * df.WIDTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73408fcf-55db-4273-8bed-895f585b1c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1dd4ed2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spark_df.write.parquet('output_1_pyspark')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308e258c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df.coalesce(1).write.parquet('output_2_pyspark')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a11bba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
